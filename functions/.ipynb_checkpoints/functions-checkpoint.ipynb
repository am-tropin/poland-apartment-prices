{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date #, datetime, timedelta\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor, VotingRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# import pickle\n",
    "# from mlflow import log_metric, log_param, log_artifact\n",
    "from mlflow.models.signature import infer_signature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41814d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    price_df4 = pd.read_csv(\"poland_apartments_completed.csv\")\n",
    "    cat_features = ['city', 'district'] # 'floor', 'rooms'?\n",
    "    num_features = ['floor', 'rooms', 'sq', 'year', 'radius']\n",
    "    target = ['price']\n",
    "    return price_df4, cat_features, num_features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4918087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b69a62ef",
   "metadata": {},
   "source": [
    "# 1. For model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_split_and_scale(df, cat_features, num_features, target):\n",
    "    X = df[cat_features + num_features]\n",
    "    y = df[target]\n",
    "\n",
    "    # encoding the categorical variables into numerical variables\n",
    "    labels_dict = {}\n",
    "    le = LabelEncoder()\n",
    "    for col in cat_features:\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        labels_dict[col] = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "    st_scaler = StandardScaler()\n",
    "    X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = st_scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, st_scaler, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e750f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_model_implementation(model, grid, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    This function:\n",
    "    - fits and returns regression model with GridSearchCV;\n",
    "    - prints confusion matrix and classification report.\n",
    "    '''\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mod = model()\n",
    "    mod_cv = GridSearchCV(mod, grid, cv=10)\n",
    "    mod_cv.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Model: {0}\".format(namestr(model, globals())[0]))\n",
    "    if grid != {}:\n",
    "        print(\"Tuned hyperparameters:\") # , mod_cv.best_params_\n",
    "        for k, v in mod_cv.best_params_.items():\n",
    "            print(\"\\t{0}: {1}\".format(k, v))\n",
    "    print()\n",
    "\n",
    "    mod = model(**mod_cv.best_params_)\n",
    "    mod.fit(X_train, y_train)\n",
    "    y_pred_mod = mod.predict(X_test)\n",
    "\n",
    "    print(\"R2-score:  \", mod.score(X_test, y_test))\n",
    "    print(\"RMSE:      \", mean_squared_error(y_test, y_pred_mod, squared=False))\n",
    "    print()\n",
    "    print(\"Time using clf_model_implementation(): {0:.4f} sec\".format(time.time() - start_time))\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(model, col_names): # list(X_train) !!!!!!! \n",
    "    '''\n",
    "    This function plots the feature importances for given model.\n",
    "    '''\n",
    "    resultdict = {}\n",
    "    importance = model.feature_importances_\n",
    "\n",
    "    print(\"score:\\t  feature:\")\n",
    "    for i in range(len(col_names)):\n",
    "        resultdict[col_names[i]] = importance[i]\n",
    "    \n",
    "    resultdict = dict(sorted(resultdict.items(), key=lambda item: -item[1]))\n",
    "    for k, v in resultdict.items():\n",
    "        print(\"{1:.3f}\\t- {0}\".format(k, v))\n",
    "\n",
    "    plt.bar(resultdict.keys(),resultdict.values())\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.show()\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4703b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa28dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2593e9be",
   "metadata": {},
   "source": [
    "# 2. For MLFlow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_cv_score(model, X_train, y_train):\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42).get_n_splits(X_train)\n",
    "    return np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=kf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track params and metrics\n",
    "def log_mlflow_run(model, signature, parameters, metrics):\n",
    "    # Auto-logging for scikit-learn estimators\n",
    "    # mlflow.sklearn.autolog()\n",
    "\n",
    "    # log estimator_name name\n",
    "    mlflow.set_tag(\"estimator_name\", model.__class__.__name__)\n",
    "\n",
    "    # log input features\n",
    "#     mlflow.set_tag(\"features\", str(X_train_scaled.tolist())) # X_train_scaled.columns.values.tolist()\n",
    "\n",
    "    # Log tracked parameters only\n",
    "    mlflow.log_params({key: model.get_params()[key] for key in parameters})\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # log training loss (ONLY FOR GradientBoostingRegressor ???)\n",
    "#     for s in model.train_score_:\n",
    "#         mlflow.log_metric(\"Train Loss\", s)\n",
    "\n",
    "    # Save model to artifacts\n",
    "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "    # log charts\n",
    "#     mlflow.log_artifacts(\"model_artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate parameters combinations\n",
    "def parameter_product(parameters):\n",
    "    params_values = [parameters[key] if isinstance(parameters[key], list) else [parameters[key]] for key in parameters.keys()]\n",
    "    return [dict(zip(parameters.keys(), combination)) for combination in itertools.product(*params_values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def training_loop(experiment, model_class, parameters, X_train_scaled, y_train, X_test_scaled, y_test):\n",
    "    runs_parameters = parameter_product(parameters)\n",
    "    model_params = {}\n",
    "    \n",
    "    for i, run_parameters in enumerate(runs_parameters):\n",
    "#         print(f\"Run {i}: {run_parameters}\")\n",
    "\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run()\n",
    "\n",
    "        # mlflow: track run\n",
    "        with mlflow.start_run(run_name=f\"Run {i}\", experiment_id=experiment.experiment_id): # , experiment_id=experiment_id\n",
    "\n",
    "            model = model_class(**run_parameters)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            # get evaluations scores\n",
    "            score = mean_squared_error(y_test, model.predict(X_test_scaled), squared=False)\n",
    "#             print(\"RMSE score: {:.4f}\".format(score))\n",
    "#             score_cv = rmsle_cv_score(model, X_train_scaled, y_train)\n",
    "#             print(\"Cross-Validation RMSE score: {:.4f} (std = {:.4f})\".format(score_cv.mean(), score_cv.std()))\n",
    "            r2 = r2_score(y_test, model.predict(X_test_scaled)) # NEW\n",
    "#             print(\"R2-score: {:.4f}\".format(r2))\n",
    "\n",
    "            # generate charts\n",
    "        #     model_feature_importance(model)\n",
    "        #     plt.close()\n",
    "        #     model_permutation_importance(model)\n",
    "        #     plt.close()\n",
    "        #     model_tree_visualization(model)\n",
    "\n",
    "            # get model signature\n",
    "            signature = infer_signature(model_input=X_train_scaled, model_output=model.predict(X_train_scaled))\n",
    "            # mlflow: log metrics\n",
    "            metrics = {\n",
    "                'RMSE': score,\n",
    "#                 'RMSE_CV': score_cv.mean(),\n",
    "                'R2': r2\n",
    "            }\n",
    "            log_mlflow_run(model, signature, parameters, metrics)\n",
    "\n",
    "#         print(\"\")\n",
    "        \n",
    "        model_params[f\"Run {i}\"] = {\n",
    "            'model': model,\n",
    "            'params': run_parameters,\n",
    "            'RMSE': score,\n",
    "#             'RMSE_CV': score_cv,\n",
    "            'R2': r2\n",
    "        }\n",
    "\n",
    "    return model_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_initialization(experiment_name):\n",
    "    # Initialize MLflow experiment\n",
    "\n",
    "    mlflow.set_tracking_uri(\"./mlruns\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "    return experiment\n",
    "\n",
    "    # experiment_name = \"poland_apartments\"\n",
    "    # experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    # mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    # delete default experiment if exits\n",
    "    # if (mlflow.get_experiment_by_name(\"Default\").lifecycle_stage == 'active'):\n",
    "    #     mlflow.delete_experiment(\"0\")\n",
    "\n",
    "    # create model_artifacts directory \n",
    "    # !mkdir -p \"model_artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c41dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f61df72d",
   "metadata": {},
   "source": [
    "# 3. For predicting by input data with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538dfc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_city_district_radius_floor_rooms(city, district, radius, floor, rooms):\n",
    "    \n",
    "    price_df4 = pd.read_csv(\"poland_apartments_completed.csv\")\n",
    "    floor_values = list(set(price_df4['floor']))\n",
    "    rooms_values = list(set(price_df4['rooms']))\n",
    "    \n",
    "    geo_df_for_check = price_df4.groupby(['city', 'district']).agg({'radius':['min','max']})\n",
    "    \n",
    "    if (city, district) not in geo_df_for_check.index:\n",
    "        print(\"Invalid city and/or district!\")\n",
    "        return False\n",
    "    else:\n",
    "        min_radius = geo_df_for_check.loc[(city, district)][('radius', 'min')]\n",
    "        max_radius = geo_df_for_check.loc[(city, district)][('radius', 'max')]\n",
    "        if not (radius >= min_radius and radius <= max_radius):\n",
    "            print(\"The radius must be between {0} and {1}\".format(round(min_radius, 2), round(max_radius, 2)))\n",
    "            return False\n",
    "        elif floor not in floor_values:\n",
    "            print(\"The floor must be integer and between {0} and {1}\".format(floor_values.min(), floor_values.max()))\n",
    "            return False\n",
    "        elif rooms not in rooms_values:\n",
    "            print(\"The rooms must be integer and between {0} and {1}\".format(rooms_values.min(), rooms_values.max()))\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "#         else:    \n",
    "#             for col in [floor, rooms]: # city, district, \n",
    "#                 if col not in list(set(price_df4[namestr(col, globals())[0]])):\n",
    "#                     print(f\"Invalid {col}\")\n",
    "#                     return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f65f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sq(sq):\n",
    "    \n",
    "    if (\n",
    "        type(sq) in [int, float] and \n",
    "        sq >= 20 and\n",
    "        sq <= 100\n",
    "    ):\n",
    "        return True\n",
    "    else:\n",
    "        print(\"The sq should be between {0} and {1}\".format(20, 100))\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd656bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_year(year, city):\n",
    "    \n",
    "    city_foundations = {\n",
    "        'Warszawa': 1300,\n",
    "        'Kraków': 990,\n",
    "        'Poznañ': 1253\n",
    "    }\n",
    "    if (\n",
    "        type(year) is int and \n",
    "        year >= city_foundations[city] and\n",
    "        year <= date.today().year\n",
    "    ):\n",
    "        return True\n",
    "    else:\n",
    "        print(\"The year should be integer and between {0} and {1}\".format(city_foundations[city], date.today().year))\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_df(city, district, radius, floor, rooms, sq, year):\n",
    "    \n",
    "    if (check_city_district_radius_floor_rooms(city, district, radius, floor, rooms)\n",
    "        and \n",
    "        check_sq(sq)\n",
    "        and \n",
    "        check_year(year, city)\n",
    "       ):\n",
    "        X_check = pd.DataFrame({\n",
    "            'city': city,\n",
    "            'district': district,\n",
    "            'floor': floor, \n",
    "            'rooms': rooms, \n",
    "            'sq': sq, \n",
    "            'year': year,\n",
    "            'radius': radius\n",
    "        }, index=[0])\n",
    "        return X_check\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_input(X_check, cat_features, st_scaler, labels_dict, model, X_test_scaled, y_test):\n",
    "    \n",
    "    for col in cat_features:\n",
    "        X_check[col] = X_check[col].apply(lambda x: labels_dict[col][x])\n",
    "\n",
    "    X_check_scaled = st_scaler.transform(X_check)\n",
    "    y_check_pred_model = model.predict(X_check_scaled)\n",
    "    \n",
    "    score = model.score(X_test_scaled, y_test)\n",
    "    price_pred = np.round(y_check_pred_model[0])\n",
    "    print(\"With a probability of {0}%, the prise will be about {1:,.0f} PLN \".format(\n",
    "        round(score * 100, 1),\n",
    "        round(price_pred)\n",
    "    ))\n",
    "    \n",
    "    return price_pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting_by_experiment(experiment, all_regressors, grids, X_train_scaled, y_train, X_test_scaled, y_test, cat_features, st_scaler, labels_dict):\n",
    "    \n",
    "    full_model_params = {}\n",
    "    \n",
    "    for reg, model_class in all_regressors.items():\n",
    "#         print(f\"{reg}:\".upper())\n",
    "        full_model_params[reg] = training_loop(experiment, model_class, grids[reg], X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "#         print()\n",
    "        \n",
    "    best_run_df = mlflow.search_runs(order_by=['metrics.R2 DESC'], max_results=1) \n",
    "    if len(best_run_df.index) == 0:\n",
    "        raise Exception(f\"Found no runs for experiment '{experiment_name}'\")\n",
    "\n",
    "    best_run = mlflow.get_run(best_run_df.at[0, 'run_id'])\n",
    "    best_model_uri = f\"{best_run.info.artifact_uri}/model\"\n",
    "    best_model = mlflow.sklearn.load_model(best_model_uri)\n",
    "\n",
    "#     print(f\"Run parameters: {best_run.data.tags['estimator_name']}\")\n",
    "#     print(f\"Run parameters: {best_run.data.params}\")\n",
    "#     print(\"Run score: R2 = {:.4f}\".format(best_run.data.metrics['R2']))\n",
    "    \n",
    "#     model_name = best_run.data.tags['estimator_name']    \n",
    "#     best_grid2 = {k: float(v) if '.' in v else int(v) for k, v in best_run.data.params.items()}\n",
    "#     best_model2 = globals()[model_name](**best_grid2)\n",
    "#     best_model2.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    X_check = input_to_df(city='Warszawa', district='Śródmieście', radius=2, floor=3, rooms=2, sq=40, year=2000)\n",
    "    \n",
    "    price_pred, score = predict_by_input(X_check, cat_features, st_scaler, labels_dict, best_model, X_test_scaled, y_test)\n",
    "    \n",
    "    return price_pred, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8388b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fecbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I NEED THE MAIN FUNCTION WITH FOLLOWING ARGMENTS:\n",
    "# (BECAUSE THESE WOULD BE INPUT FROM HTML FORM)\n",
    "    \n",
    "def main_predicting(city, district, radius, floor, rooms, sq, year):\n",
    "    \n",
    "    X_check = input_to_df(city='Warszawa', district='Śródmieście', radius=2, floor=3, rooms=2, sq=40, year=2000)\n",
    "    \n",
    "    \n",
    "    !!!!!!!!!!\n",
    "    !!!!!!!!!!\n",
    "    !!!!!!!!!!\n",
    "    !!!!!!!!!!\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
