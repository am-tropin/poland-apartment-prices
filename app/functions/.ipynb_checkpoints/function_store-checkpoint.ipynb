{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e9b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date #, datetime, timedelta\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor, VotingRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# import pickle\n",
    "# from mlflow import log_metric, log_param, log_artifact\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# from IPython import get_ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef151508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POLAND_APARTMENTS_FILE = \"poland_apartments_completed.csv\"\n",
    "# POLAND_APARTMENTS_DF = pd.read_csv(POLAND_APARTMENTS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e50b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(apartments_df):\n",
    "#     apartments_df = pd.read_csv(apartments_file)\n",
    "    cat_features = ['city', 'district'] # 'floor', 'rooms'?\n",
    "    num_features = ['floor', 'rooms', 'sq', 'year', 'radius']\n",
    "    target = ['price']\n",
    "    return apartments_df, cat_features, num_features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc35ce",
   "metadata": {},
   "source": [
    "# 1. For model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_split_and_scale(df, cat_features, num_features, target):\n",
    "    X = df[cat_features + num_features]\n",
    "    y = df[target]\n",
    "\n",
    "    # encoding the categorical variables into numerical variables\n",
    "    labels_dict = {}\n",
    "    le = LabelEncoder()\n",
    "    for col in cat_features:\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        labels_dict[col] = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "    st_scaler = StandardScaler()\n",
    "    X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = st_scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, st_scaler, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6aa5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_model_implementation(model, grid, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This function:\n",
    "    - fits and returns regression model with GridSearchCV;\n",
    "    - prints confusion matrix and classification report.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    mod = model()\n",
    "    mod_cv = GridSearchCV(mod, grid, cv=10)\n",
    "    mod_cv.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Model: {0}\".format(namestr(model, globals())[0]))\n",
    "    if grid != {}:\n",
    "        print(\"Tuned hyperparameters:\") # , mod_cv.best_params_\n",
    "        for k, v in mod_cv.best_params_.items():\n",
    "            print(\"\\t{0}: {1}\".format(k, v))\n",
    "    print()\n",
    "\n",
    "    mod = model(**mod_cv.best_params_)\n",
    "    mod.fit(X_train, y_train)\n",
    "    y_pred_mod = mod.predict(X_test)\n",
    "\n",
    "    print(\"R2-score:  \", mod.score(X_test, y_test))\n",
    "    print(\"RMSE:      \", mean_squared_error(y_test, y_pred_mod, squared=False))\n",
    "    print()\n",
    "    print(\"Time using clf_model_implementation(): {0:.4f} sec\".format(time.time() - start_time))\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(model, col_names): # list(X_train) !!!!!!! \n",
    "    \"\"\"\n",
    "    This function plots the feature importances for given model.\n",
    "    \"\"\"\n",
    "    resultdict = {}\n",
    "    importance = model.feature_importances_\n",
    "\n",
    "    print(\"score:\\t  feature:\")\n",
    "    for i in range(len(col_names)):\n",
    "        resultdict[col_names[i]] = importance[i]\n",
    "    \n",
    "    resultdict = dict(sorted(resultdict.items(), key=lambda item: -item[1]))\n",
    "    for k, v in resultdict.items():\n",
    "        print(\"{1:.3f}\\t- {0}\".format(k, v))\n",
    "\n",
    "    plt.bar(resultdict.keys(),resultdict.values())\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c73ec0b",
   "metadata": {},
   "source": [
    "# 2. For MLFlow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a832b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_cv_score(model, X_train, y_train):\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42).get_n_splits(X_train)\n",
    "    return np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=kf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f649b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track params and metrics\n",
    "def log_mlflow_run(model, signature, parameters, metrics):\n",
    "    # Auto-logging for scikit-learn estimators\n",
    "    # mlflow.sklearn.autolog()\n",
    "\n",
    "    # log estimator_name name\n",
    "    mlflow.set_tag(\"estimator_name\", model.__class__.__name__)\n",
    "\n",
    "    # log input features\n",
    "#     mlflow.set_tag(\"features\", str(X_train_scaled.tolist())) # X_train_scaled.columns.values.tolist()\n",
    "\n",
    "    # Log tracked parameters only\n",
    "    mlflow.log_params({key: model.get_params()[key] for key in parameters})\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # log training loss (ONLY FOR GradientBoostingRegressor ???)\n",
    "#     for s in model.train_score_:\n",
    "#         mlflow.log_metric(\"Train Loss\", s)\n",
    "\n",
    "    # Save model to artifacts\n",
    "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "    # log charts\n",
    "#     mlflow.log_artifacts(\"model_artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d207e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate parameters combinations\n",
    "def parameter_product(parameters):\n",
    "    params_values = [parameters[key] if isinstance(parameters[key], list) else [parameters[key]] for key in parameters.keys()]\n",
    "    return [dict(zip(parameters.keys(), combination)) for combination in itertools.product(*params_values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffffa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def training_loop(experiment, model_class, parameters, scaled_arrays):\n",
    "    runs_parameters = parameter_product(parameters)\n",
    "    model_params = {}\n",
    "    X_train_scaled, y_train, X_test_scaled, y_test = scaled_arrays\n",
    "    \n",
    "    for i, run_parameters in enumerate(runs_parameters):\n",
    "#         print(f\"Run {i}: {run_parameters}\")\n",
    "\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run()\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"Run {i}\", experiment_id=experiment.experiment_id): # , experiment_id=experiment_id\n",
    "\n",
    "            model = model_class(**run_parameters)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            score = mean_squared_error(y_test, model.predict(X_test_scaled), squared=False)\n",
    "#             print(\"RMSE score: {:.4f}\".format(score))\n",
    "#             score_cv = rmsle_cv_score(model, X_train_scaled, y_train)\n",
    "#             print(\"Cross-Validation RMSE score: {:.4f} (std = {:.4f})\".format(score_cv.mean(), score_cv.std()))\n",
    "            r2 = r2_score(y_test, model.predict(X_test_scaled)) # NEW\n",
    "#             print(\"R2-score: {:.4f}\".format(r2))\n",
    "\n",
    "            # generate charts\n",
    "        #     model_feature_importance(model)\n",
    "        #     plt.close()\n",
    "        #     model_permutation_importance(model)\n",
    "        #     plt.close()\n",
    "        #     model_tree_visualization(model)\n",
    "\n",
    "            # get model signature\n",
    "            signature = infer_signature(model_input=X_train_scaled, model_output=model.predict(X_train_scaled))\n",
    "            # mlflow: log metrics\n",
    "            metrics = {\n",
    "                'RMSE': score,\n",
    "#                 'RMSE_CV': score_cv.mean(),\n",
    "                'R2': r2\n",
    "            }\n",
    "            log_mlflow_run(model, signature, parameters, metrics)\n",
    "\n",
    "#         print(\"\")\n",
    "        \n",
    "        model_params[f\"Run {i}\"] = {\n",
    "            'model': model,\n",
    "            'params': run_parameters,\n",
    "            'RMSE': score,\n",
    "#             'RMSE_CV': score_cv,\n",
    "            'R2': r2\n",
    "        }\n",
    "\n",
    "    return model_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fed6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_initialization(experiment_name):\n",
    "    # Initialize MLflow experiment\n",
    "\n",
    "    mlflow.set_tracking_uri(\"./mlruns\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "    return experiment\n",
    "\n",
    "    # experiment_name = \"poland_apartments\"\n",
    "    # experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    # mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    # delete default experiment if exits\n",
    "    # if (mlflow.get_experiment_by_name(\"Default\").lifecycle_stage == 'active'):\n",
    "    #     mlflow.delete_experiment(\"0\")\n",
    "\n",
    "    # create model_artifacts directory \n",
    "    # !mkdir -p \"model_artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e67b87",
   "metadata": {},
   "source": [
    "# 3. For predicting by input data with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c00325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_city_district_radius_floor_rooms(apartments_df, city, district, radius, floor, rooms):\n",
    "    \n",
    "#     price_df4 = pd.read_csv(apartments_file)\n",
    "#     price_df4 = apartments_df\n",
    "    floor_values = list(set(apartments_df['floor']))\n",
    "    rooms_values = list(set(apartments_df['rooms']))\n",
    "    \n",
    "    geo_df_for_check = apartments_df.groupby(['city', 'district']).agg({'radius':['min','max']})\n",
    "    \n",
    "    if (city, district) not in geo_df_for_check.index:\n",
    "        print(\"Invalid city and/or district!\")\n",
    "        return False\n",
    "    else:\n",
    "        min_radius = geo_df_for_check.loc[(city, district)][('radius', 'min')]\n",
    "        max_radius = geo_df_for_check.loc[(city, district)][('radius', 'max')]\n",
    "        if not (radius >= min_radius and radius <= max_radius):\n",
    "            print(\"The radius must be between {0} and {1}\".format(round(min_radius, 2), round(max_radius, 2)))\n",
    "            return False\n",
    "        elif floor not in floor_values:\n",
    "            print(\"The floor must be integer and between {0} and {1}\".format(floor_values.min(), floor_values.max()))\n",
    "            return False\n",
    "        elif rooms not in rooms_values:\n",
    "            print(\"The rooms must be integer and between {0} and {1}\".format(rooms_values.min(), rooms_values.max()))\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "#         else:    \n",
    "#             for col in [floor, rooms]: # city, district, \n",
    "#                 if col not in list(set(price_df4[namestr(col, globals())[0]])):\n",
    "#                     print(f\"Invalid {col}\")\n",
    "#                     return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c11ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sq(sq):\n",
    "    \n",
    "    if (\n",
    "        type(sq) in [int, float] and \n",
    "        sq >= 20 and sq <= 100\n",
    "    ):\n",
    "        return True\n",
    "    else:\n",
    "        print(\"The sq should be between {0} and {1}\".format(20, 100))\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aca17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_year(year, city):\n",
    "    \n",
    "    city_foundations = {\n",
    "        'Warszawa': 1300,\n",
    "        'Kraków': 990,\n",
    "        'Poznañ': 1253\n",
    "    }\n",
    "    if (\n",
    "        type(year) is int and \n",
    "        year >= city_foundations[city] and year <= date.today().year\n",
    "    ):\n",
    "        return True\n",
    "    else:\n",
    "        print(\"The year should be integer and between {0} and {1}\".format(city_foundations[city], date.today().year))\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_df(apartments_df, city, district, radius, floor, rooms, sq, year):\n",
    "    \n",
    "    if (check_city_district_radius_floor_rooms(apartments_df, city, district, radius, floor, rooms) and \n",
    "        check_sq(sq) and \n",
    "        check_year(year, city)\n",
    "       ):\n",
    "        return pd.DataFrame({\n",
    "            'city': city,\n",
    "            'district': district,\n",
    "            'floor': floor, \n",
    "            'rooms': rooms, \n",
    "            'sq': sq, \n",
    "            'year': year,\n",
    "            'radius': radius\n",
    "        }, index=[0])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a157e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_regressors():\n",
    "\n",
    "    all_regressors = {\n",
    "    #     'linreg': LinearRegression,\n",
    "    #     'ridge': Ridge,\n",
    "    #     'lasso': Lasso,\n",
    "    #     'knn': KNeighborsRegressor,\n",
    "    #     'tree': DecisionTreeRegressor,\n",
    "    #     'gbr': GradientBoostingRegressor,\n",
    "        'xgb': XGBRegressor\n",
    "    }\n",
    "\n",
    "    grids = {\n",
    "        'linreg': {},\n",
    "        'ridge': {\n",
    "            \"alpha\": [0.0001], # list(np.logspace(-4, -1, 4))\n",
    "            \"solver\": [\"lsqr\"] # [\"sag\", \"lsqr\"]\n",
    "        },\n",
    "        'lasso': {\n",
    "            \"alpha\": [0.0001], # list(np.logspace(-4, 2, 7))\n",
    "            \"max_iter\": [1000]\n",
    "        },\n",
    "        'knn': {\n",
    "            \"n_neighbors\": [10], # [8, 9, 10]\n",
    "            \"leaf_size\": [30], # [25, 30, 35]\n",
    "            \"p\": [2]\n",
    "#             \"algorithm\": ['auto']\n",
    "        },\n",
    "        'tree': {\n",
    "            \"min_samples_split\": [15], # [10, 15, 20, 25]\n",
    "            \"max_depth\": [8], # [6, 8]\n",
    "        #     \"criterion\": ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "            \"splitter\": ['best'] # , 'random'\n",
    "        },\n",
    "        'gbr': {\n",
    "            \"learning_rate\": [0.2], # [0.2, 0.1, 0.05]\n",
    "            \"max_depth\": [5, 6, 7] # [5, 6, 7, 8]\n",
    "        },\n",
    "        'xgb': {\n",
    "            \"max_depth\": [8], # [6, 7, 8, 9]\n",
    "            \"n_estimators\": [200, 300],\n",
    "            \"learning_rate\": [0.2] # [0.2, 0.1, 0.05]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return all_regressors, grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c50cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_model(experiment, all_regressors, grids, scaled_arrays):\n",
    "    \n",
    "#     full_model_params = {}\n",
    "    for reg, model_class in all_regressors.items():\n",
    "#         full_model_params[reg] = training_loop(experiment, model_class, grids[reg], X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "        training_loop(experiment, model_class, grids[reg], scaled_arrays)\n",
    "    \n",
    "    best_run_df = mlflow.search_runs(order_by=['metrics.R2 DESC'], max_results=1) \n",
    "    if len(best_run_df.index) == 0:\n",
    "        raise Exception(f\"Found no runs for experiment '{experiment_name}'\")\n",
    "    \n",
    "    best_run = mlflow.get_run(best_run_df.at[0, 'run_id'])\n",
    "    best_model_uri = f\"{best_run.info.artifact_uri}/model\"\n",
    "    best_model = mlflow.sklearn.load_model(best_model_uri)\n",
    "    \n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e98e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_input(X_check, cat_features, st_scaler, labels_dict, model, X_test_scaled, y_test):\n",
    "    \n",
    "    for col in cat_features:\n",
    "        X_check[col] = X_check[col].apply(lambda x: labels_dict[col][x])\n",
    "\n",
    "    X_check_scaled = st_scaler.transform(X_check)\n",
    "    y_check_pred_model = model.predict(X_check_scaled)\n",
    "    \n",
    "    score = model.score(X_test_scaled, y_test)\n",
    "    price_pred = np.round(y_check_pred_model[0])\n",
    "    print(\"With a probability of {0}%, the price will be about {1:,.0f} PLN \".format(\n",
    "        round(score * 100, 1),\n",
    "        round(price_pred)\n",
    "    ))\n",
    "    \n",
    "    return price_pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0249c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_predicting(city, district, radius, floor, rooms, sq, year, apartments_df): # apartments_df=POLAND_APARTMENTS_DF\n",
    "    \n",
    "    X_check = input_to_df(apartments_df=apartments_df, city='Warszawa', district='Śródmieście', radius=2, floor=3, rooms=2, sq=40, year=2000)\n",
    "    if X_check is not None:\n",
    "        price_df4, cat_features, num_features, target = load_data()\n",
    "        experiment = experiment_initialization(\"poland_apartments\")\n",
    "        all_regressors, grids = set_regressors()\n",
    "\n",
    "        # run tracking UI in the background\n",
    "    #     get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
    "\n",
    "        X_train_scaled, X_test_scaled, y_train, y_test, st_scaler, labels_dict = to_split_and_scale(price_df4, cat_features, num_features, target)\n",
    "        scaled_arrays = [X_train_scaled, y_train, X_test_scaled, y_test]\n",
    "        best_model = select_best_model(experiment, all_regressors, grids, scaled_arrays)\n",
    "        price_pred, score = predict_by_input(X_check, cat_features, st_scaler, labels_dict, best_model, X_test_scaled, y_test)\n",
    "\n",
    "        return \"With a probability of {0}%, the price will be about {1:,.0f} PLN.\".format(round(score * 100, 1), round(price_pred))\n",
    "    else:\n",
    "        return \"Invalid input :(\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd104a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7bcdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07802d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predicting_by_experiment(experiment, all_regressors, grids, X_train_scaled, y_train, X_test_scaled, y_test, cat_features, st_scaler, labels_dict):\n",
    "    \n",
    "#     full_model_params = {}\n",
    "    \n",
    "#     for reg, model_class in all_regressors.items():\n",
    "# #         print(f\"{reg}:\".upper())\n",
    "#         full_model_params[reg] = training_loop(experiment, model_class, grids[reg], X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "# #         print()\n",
    "        \n",
    "#     best_run_df = mlflow.search_runs(order_by=['metrics.R2 DESC'], max_results=1) \n",
    "#     if len(best_run_df.index) == 0:\n",
    "#         raise Exception(f\"Found no runs for experiment '{experiment_name}'\")\n",
    "\n",
    "#     best_run = mlflow.get_run(best_run_df.at[0, 'run_id'])\n",
    "#     best_model_uri = f\"{best_run.info.artifact_uri}/model\"\n",
    "#     best_model = mlflow.sklearn.load_model(best_model_uri)\n",
    "\n",
    "# #     print(f\"Run parameters: {best_run.data.tags['estimator_name']}\")\n",
    "# #     print(f\"Run parameters: {best_run.data.params}\")\n",
    "# #     print(\"Run score: R2 = {:.4f}\".format(best_run.data.metrics['R2']))\n",
    "    \n",
    "# #     model_name = best_run.data.tags['estimator_name']    \n",
    "# #     best_grid2 = {k: float(v) if '.' in v else int(v) for k, v in best_run.data.params.items()}\n",
    "# #     best_model2 = globals()[model_name](**best_grid2)\n",
    "# #     best_model2.fit(X_train_scaled, y_train)\n",
    "    \n",
    "#     X_check = input_to_df(city='Warszawa', district='Śródmieście', radius=2, floor=3, rooms=2, sq=40, year=2000)\n",
    "    \n",
    "#     price_pred, score = predict_by_input(X_check, cat_features, st_scaler, labels_dict, best_model, X_test_scaled, y_test)\n",
    "    \n",
    "#     return price_pred, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f45f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_feature_importance(model):\n",
    "#     feature_importance = pd.DataFrame(\n",
    "#         model.feature_importances_,\n",
    "#         index=X_train_scaled, # X_train_scaled.columns\n",
    "#         columns=[\"Importance\"],\n",
    "#     )\n",
    "\n",
    "#     # sort by importance\n",
    "#     feature_importance.sort_values(by=\"Importance\", ascending=False, inplace=True)\n",
    "\n",
    "#     # plot\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     sns.barplot(\n",
    "#         data=feature_importance.reset_index(),\n",
    "#         y=\"index\",\n",
    "#         x=\"Importance\",\n",
    "#     ).set_title(\"Feature Importance\")\n",
    "#     # save image\n",
    "#     plt.savefig(\"model_artifacts/feature_importance.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_permutation_importance(model):\n",
    "#     p_importance = permutation_importance(model, X_test_scaled, y_test, random_state=42, n_jobs=-1)\n",
    "\n",
    "#     # sort by importance\n",
    "#     sorted_idx = p_importance.importances_mean.argsort()[::-1]\n",
    "#     p_importance = pd.DataFrame(\n",
    "#         data=p_importance.importances[sorted_idx].T,\n",
    "#         columns=X_train.columns[sorted_idx]\n",
    "#     )\n",
    "\n",
    "#     # plot\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     sns.barplot(\n",
    "#         data=p_importance,\n",
    "#         orient=\"h\"\n",
    "#     ).set_title(\"Permutation Importance\")\n",
    "\n",
    "#     # save image\n",
    "#     plt.savefig(\"model_artifacts/permutation_importance.png\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
